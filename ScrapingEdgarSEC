from lxml import html, etree
from urllib.parse import urlparse
import requests
import pymongo
from pymongo import MongoClient


def sec10k_url(cik_number, date):

        base_url = r"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK="
        list_10k = base_url + str(cik_number) + '&type=10-k&dateb=' + str(date+1) + '0601&owner=exclude&count=40&search_text='
        page = requests.get(list_10k)
        webpage = html.fromstring(page.content)
        bridge = webpage.xpath('//a/@href')
        bridge = ["https://www.sec.gov" + x for x in bridge if x[0:6] == '/Archi']

        return bridge[0]


def sec10q_url(cik_number, date, quarter=None):

    base_url = r"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK="
    list_10q = base_url + str(cik_number) + '&type=10-q&dateb=' + str(date + 1) + '1231&owner=exclude&count=40&search_text='
    page = requests.get(list_10q)
    webpage = html.fromstring(page.content)
    bridge = webpage.xpath('//a/@href')
    bridge = ["https://www.sec.gov" + x for x in bridge if x[0:6] == '/Archi']
    file10q = []

    if quarter is not None:
        for i in range(len(bridge)):
            page10q = requests.get(bridge[i])
            tree = etree.HTML(page10q.text)
            element = tree.xpath('normalize-space(//*[@id="formDiv"]/div[2]/div[2]/div[2]/text())')
            if str(date) in str(element):
                qtr = str(element)[5:7]
                if qtr == '01' or qtr == '02' or qtr == '03':
                    q = '1'
                if qtr == '04' or qtr == '05' or qtr == '06':
                    q = '2'
                if qtr == '07' or qtr == '08' or qtr == '09':
                    q = '3'
                if qtr == '10' or qtr == '11' or qtr == '12':
                    q = '4'
                if q == str(quarter):
                    file10q.append(bridge[i])

        return file10q[0]
    else:

        return bridge[0], bridge[1], bridge[2], bridge[3]


def sec8k_url(cik_number, date):

        base_url = r"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK="
        list_10k = base_url + str(cik_number) + '&type=8-k&dateb=' + str(date+1) + '0601&owner=exclude&count=40&search_text='
        page = requests.get(list_10k)
        webpage = html.fromstring(page.content)
        bridge = webpage.xpath('//a/@href')
        bridge = ["https://www.sec.gov" + x for x in bridge if x[0:6] == '/Archi']

        return bridge[0]


def sec_exhibit(link=(sec10k_url, sec10q_url, sec8k_url)):

    resp = requests.get(link)
    body = resp.text
    entries = body.split("<table")[1].split("table>")[0].split("<a href=")
    links_parsed = []

    for i in range(len(entries)):
        if i != 0 and i != len(entries):
            raw_link = entries[i].split(">")[0]
            last_element_in_link = raw_link.split("/")[-1]
            if last_element_in_link != "\"":
                link = "https://www.sec.gov" + raw_link.replace("\"", "")
                links_parsed.append(link)

    return links_parsed


def download_exhibits(sec_exhibit, file_name):

    name_files = []
    for i in range(len(sec_exhibit)):
        file = requests.get(sec_exhibit[i])
        with open('/Users/SEC_files/' + str(file_name) + str(i) + '.txt', 'wb') as f:
            f.write(file.content)
            name_files.append('/Users/SEC_files/' + str(file_name) + str(i) + '.txt')
    return name_files


def download_exhibits10(sec_exhibit, file_name):

    name_files = []
    for i in range(len(sec_exhibit)):
        wanted_files = urlparse(sec_exhibit[i])
        if 'x10' in wanted_files.path or 'exh10' in wanted_files.path:
            file = requests.get(sec_exhibit[i])
            with open('/Users/marco/Desktop/SEC_files/' + str(file_name) + str(i) + '.txt', 'wb') as f:
                f.write(file.content)
                name_files.append('/Users/SEC_files/' + str(file_name) + str(i) + '.txt')
    return name_files


def file_parser(file_name, name):

    with open(file_name, 'r') as rf:
        with open('/Users/marco/Desktop/SEC_files/relevant_info_' + str(name) + '.txt', 'w+') as wf:
            for line in rf:
                if ('credit facility' in line or
                        'bank loan' in line or
                        'credit agreement' in line or
                        'credit line' in line or
                        'loan facility' in line or
                        'syndicate' in line):
                    wf.write(line + '\n')


def mongo_this(sec_exhibit, id_post, id_mongo, password_mongo):
    cluster = MongoClient(
        "mongodb+srv://"+str(id_mongo)+':'+str(password_mongo)+"@cluster0.y6wkl.mongodb.net/<dbname>?retryWrites=true&w=majority")
    db = cluster["test"]
    collection = db["test"]
    for i in range(len(sec_exhibit)):
        file = requests.get(sec_exhibit[i])
        content = file.text
        post = {"_id": i, 'content': content}
        collection.insert_one(post)

#here are some output functions to try and understand, always rembember to change your credentials for mongodb and select the correct file path
#file_parser('/Users/SEC_files/exh10_1')
#print(sec10k_url(730469, 2005))
#print(sec_exhibit(sec10k_url(730469, 2005)))
#print(download_exhibits10(sec_exhibit(sec10k_url(730469, 2005)), '730469_exhibit10_'))
#mongo_this(sec_exhibit(sec10k_url(730469, 2005)))
#print(sec10q_url(201493, 1994, 2))
#print(sec8k_url(201493, 1994))
#print(sec_exhibit(sec8k_url(201493, 1994)))
